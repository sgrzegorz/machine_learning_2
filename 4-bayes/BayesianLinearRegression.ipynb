{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17387b3c-8c65-478f-91bb-1a10276683dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e3d3cb-c375-4247-bfe5-8315a298f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (13,13) (303,303) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_522143/3221086895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mblr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mblr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mblr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_522143/3221086895.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Update the inverse covariance matrix (\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Equation 77# Update the mean vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m  \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (13,13) (303,303) "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class BayesianLinearRegression:\n",
    "    def __init__(self, n_features, alpha, beta):\n",
    "        self.n_features = n_features\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.mean = np.zeros(n_features)\n",
    "        self.cov = np.identity(n_features) * alpha\n",
    "    \n",
    "    def learn(self, x, y):\n",
    "        # Update the inverse covariance matrix (\n",
    "        # Equation 77# Update the mean vector\n",
    "        cov = inv(inv(self.cov) + self.beta * x @ np.transpose(x))\n",
    "        self.cov = cov\n",
    "        self.mean = self.cov @ (inv(cov) @ self.mean +  self.beta * y  @ x)\n",
    "        \n",
    "        # Equation 78\n",
    "        return self\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # Obtain the predictive mean\n",
    "        # Equation 62, Equation 80\n",
    "        # Obtain the predictive variance\n",
    "        # Equation 81\n",
    "        y_pred_mean = self.weights_dist().T @ x\n",
    "        y_pred_var = 1/ self.beta + x.T @ self.cov @ x\n",
    "                             \n",
    "        return stats.norm(loc=y_pred_mean, scale=y_pred_var ** .5)\n",
    "    \n",
    "    @property\n",
    "    def weights_dist(self):\n",
    "        return stats.multivariate_normal(mean=self.mean, cov=self.cov)\n",
    "    \n",
    "X, y = load_boston(return_X_y=True)\n",
    "n_features  = len(load_boston()['feature_names'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "blr = BayesianLinearRegression(n_features ,0.3, 1.0)\n",
    "blr.learn(X_train,y_train)\n",
    "blr.predict(X_test[0],y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98228484-3912-4987-a5bf-ccaf9e53a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatywna pr√≥ba\n",
    "\n",
    "# class BayesianLinearRegression:\n",
    "#     def __init__(self, n_features, alpha, beta):\n",
    "#         self.n_features = n_features\n",
    "#         self.alpha = alpha\n",
    "#         self.beta = beta\n",
    "#         self.mean = np.zeros(n_features)\n",
    "#         self.cov = np.identity(n_features) * alpha\n",
    "\n",
    "#     def learn(self, x, y):\n",
    "#         # Update the inverse covariance matrix (\n",
    "#         # Equation 77# Update the mean vector\n",
    "#         cov = inv(inv(self.cov) + self.beta * x @ np.transpose(x))\n",
    "#         self.cov = np.copy(cov)\n",
    "#         t = np.transpose(self.weights_dist()) @ x\n",
    "#         self.mean = self.cov @ (inv(cov) @ self.mean + self.beta * t @ x)\n",
    "\n",
    "#         # Equation 78\n",
    "#         return self\n",
    "\n",
    "#     def fit(self,X_train,y_train):\n",
    "#         for i in range(len(y_train)):\n",
    "#             self.learn(X_train[i],y_train[i])\n",
    "\n",
    "#     def predict(self, x):\n",
    "#         # Obtain the predictive mean\n",
    "#         # Equation 62, Equation 80\n",
    "#         # Obtain the predictive variance\n",
    "#         # Equation 81\n",
    "#         y_pred_mean = self.weights_dist().T @ x\n",
    "#         y_pred_var = 1 / self.beta + x.T @ self.cov @ x\n",
    "\n",
    "#         return stats.norm(loc=y_pred_mean, scale=y_pred_var ** .5)\n",
    "\n",
    "#     @property\n",
    "#     def weights_dist(self):\n",
    "#         return stats.multivariate_normal(mean=self.mean, cov=self.cov)\n",
    "\n",
    "\n",
    "# X, y = load_boston(return_X_y=True)\n",
    "# n_features = len(load_boston()['feature_names'])\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "# blr = BayesianLinearRegression(n_features, 0.3, 1.0)\n",
    "# blr.fit(X_train, y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
